{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78233f0-ef67-45e3-958c-d9b727c5925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando coleta de 7 dias: 2025-05-19 até 2025-05-26\n",
      "======================================================================\n",
      "\n",
      "Processando data: 2025-05-19\n",
      "  WDO$N M5: Arquivo já existe\n",
      "  WDO$N M15: Arquivo já existe\n",
      "  WDO$N H1: Arquivo já existe\n",
      "  WDO$N M2: Arquivo já existe\n",
      "  WDO$N D1: Arquivo já existe\n",
      "  Coletando WDO$N W1... Sem dados\n",
      "  Coletando WDO$N MN1... Sem dados\n",
      "\n",
      "Processando data: 2025-05-20\n",
      "  WDO$N M5: Arquivo já existe\n",
      "  WDO$N M15: Arquivo já existe\n",
      "  WDO$N H1: Arquivo já existe\n",
      "  WDO$N M2: Arquivo já existe\n",
      "  WDO$N D1: Arquivo já existe\n",
      "  Coletando WDO$N W1... Sem dados\n",
      "  Coletando WDO$N MN1... Sem dados\n",
      "\n",
      "Processando data: 2025-05-21\n",
      "  WDO$N M5: Arquivo já existe\n",
      "  WDO$N M15: Arquivo já existe\n",
      "  WDO$N H1: Arquivo já existe\n",
      "  WDO$N M2: Arquivo já existe\n",
      "  WDO$N D1: Arquivo já existe\n",
      "  Coletando WDO$N W1... Sem dados\n",
      "  Coletando WDO$N MN1... Sem dados\n",
      "\n",
      "Processando data: 2025-05-22\n",
      "  WDO$N M5: Arquivo já existe\n",
      "  WDO$N M15: Arquivo já existe\n",
      "  WDO$N H1: Arquivo já existe\n",
      "  WDO$N M2: Arquivo já existe\n",
      "  WDO$N D1: Arquivo já existe\n",
      "  Coletando WDO$N W1... Sem dados\n",
      "  Coletando WDO$N MN1... Sem dados\n",
      "\n",
      "Processando data: 2025-05-23\n",
      "  WDO$N M5: Arquivo já existe\n",
      "  WDO$N M15: Arquivo já existe\n",
      "  WDO$N H1: Arquivo já existe\n",
      "  WDO$N M2: Arquivo já existe\n",
      "  Coletando WDO$N D1... Sem dados\n",
      "  Coletando WDO$N W1... Sem dados\n",
      "  Coletando WDO$N MN1... Sem dados\n",
      "\n",
      "Processando data: 2025-05-24\n",
      "  Coletando WDO$N M5... Sem dados\n",
      "  Coletando WDO$N M15... "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MetaTrader5 as mt5\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "import ta  # IMPORTANTE: garantir que está importado!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = \"C://Users//thiag//OneDrive//ARQUIVOS//Bolsa//COLETA//MT//FUTUROS\"\n",
    "\n",
    "TIMEFRAMES = {\n",
    "    'M5': mt5.TIMEFRAME_M5,\n",
    "    'M15': mt5.TIMEFRAME_M15,\n",
    "    'H1': mt5.TIMEFRAME_H1,\n",
    "    'M2': mt5.TIMEFRAME_M2,\n",
    "    'D1': mt5.TIMEFRAME_D1,    # Diário\n",
    "    'W1': mt5.TIMEFRAME_W1,    # Semanal\n",
    "    'MN1': mt5.TIMEFRAME_MN1   # Mensal\n",
    "}\n",
    "\n",
    "def adicionar_colunas_avancadas(df):\n",
    "        for col in ['ÚLT. PREÇO', 'PREÇO ABERT.', 'PREÇO MÍN.', 'PREÇO MÁX.', 'VOL.']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "        # log_return\n",
    "        df['log_return'] = np.log(df['ÚLT. PREÇO'] / df['ÚLT. PREÇO'].shift(1))\n",
    "        # vol_ratio_10 e vol_ratio_20\n",
    "        df['vol_ratio_10'] = df['VOL.'] / df['VOL.'].rolling(10).mean()\n",
    "        df['vol_ratio_20'] = df['VOL.'] / df['VOL.'].rolling(20).mean()\n",
    "        # RSI 14 e RSI 21\n",
    "        df['rsi_14'] = ta.momentum.RSIIndicator(df['ÚLT. PREÇO'], window=14).rsi()\n",
    "        df['rsi_21'] = ta.momentum.RSIIndicator(df['ÚLT. PREÇO'], window=21).rsi()\n",
    "        # Volatility (desvio padrão do preço de fechamento)\n",
    "        df['volatility_10'] = df['ÚLT. PREÇO'].rolling(window=10).std()\n",
    "        df['volatility_20'] = df['ÚLT. PREÇO'].rolling(window=20).std()\n",
    "        # Momentum 5 e 10\n",
    "        df['momentum_5'] = ta.momentum.roc(df['ÚLT. PREÇO'], window=5)\n",
    "        df['momentum_10'] = ta.momentum.roc(df['ÚLT. PREÇO'], window=10)\n",
    "        # SMA 13 e EMA 21\n",
    "        df['sma_13'] = df['ÚLT. PREÇO'].rolling(window=13).mean()\n",
    "        df['ema_21'] = df['ÚLT. PREÇO'].ewm(span=21, adjust=False).mean()\n",
    "        # price_vs_sma_13 e price_vs_ema_21\n",
    "        df['price_vs_sma_13'] = (df['ÚLT. PREÇO'] - df['sma_13']) / df['sma_13']\n",
    "        df['price_vs_ema_21'] = (df['ÚLT. PREÇO'] - df['ema_21']) / df['ema_21']\n",
    "        # Bandas de Bollinger 20 períodos\n",
    "        bb = ta.volatility.BollingerBands(df['ÚLT. PREÇO'], window=20)\n",
    "        df['bb_position_20'] = (df['ÚLT. PREÇO'] - bb.bollinger_lband()) / (bb.bollinger_hband() - bb.bollinger_lband())\n",
    "        # high_low_ratio\n",
    "        df['high_low_ratio'] = df['PREÇO MÁX.'] / df['PREÇO MÍN.']\n",
    "        # open_close_ratio\n",
    "        df['open_close_ratio'] = df['PREÇO ABERT.'] / df['ÚLT. PREÇO']\n",
    "        # body_ratio\n",
    "        df['body_ratio'] = (df['ÚLT. PREÇO'] - df['PREÇO ABERT.']) / (df['PREÇO MÁX.'] - df['PREÇO MÍN.'])\n",
    "        # price_position\n",
    "        df['price_position'] = (df['ÚLT. PREÇO'] - df['PREÇO MÍN.']) / (df['PREÇO MÁX.'] - df['PREÇO MÍN.'])\n",
    "        # correlation_lag_1\n",
    "        df['correlation_lag_1'] = df['ÚLT. PREÇO'].rolling(window=2).corr(df['ÚLT. PREÇO'].shift(1))\n",
    "        # Remover colunas auxiliares se quiser\n",
    "        df.drop(['sma_13', 'ema_21'], axis=1, inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "class MTDataCollector:\n",
    "    def __init__(self):\n",
    "        if not mt5.initialize():\n",
    "            print(\"MetaTrader5 não iniciou, erro:\", mt5.last_error())\n",
    "            raise Exception(\"Falha na inicialização do MetaTrader5\")\n",
    "        \n",
    "        os.makedirs(DATA_DIR, exist_ok=True)\n",
    "        self.existing_files = self.get_existing_files()\n",
    "    \n",
    "    def __del__(self):\n",
    "        mt5.shutdown()\n",
    "\n",
    "    def get_existing_files(self):\n",
    "        \"\"\"Mapeia arquivos existentes\"\"\"\n",
    "        files = glob.glob(os.path.join(DATA_DIR, 'WDO*.csv'))\n",
    "        return {os.path.basename(f) for f in files}\n",
    "\n",
    "    def get_timeframe_data(self, symbol, timeframe, date):\n",
    "        \"\"\"Coleta dados de um timeframe específico para uma data\"\"\"\n",
    "        start_time = datetime(date.year, date.month, date.day, 6, 0)\n",
    "        end_time = datetime(date.year, date.month, date.day, 21, 00)\n",
    "        \n",
    "        try:\n",
    "            rates = mt5.copy_rates_range(symbol, timeframe, start_time, end_time)\n",
    "            if rates is None or len(rates) == 0:\n",
    "                return None\n",
    "                \n",
    "            df = pd.DataFrame(rates)\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao coletar {symbol} em {timeframe} para {date.date()}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def process_data(self, df):\n",
    "        \"\"\"Processa e adiciona indicadores aos dados\"\"\"\n",
    "        if df is None or len(df) == 0:\n",
    "            return None\n",
    "            \n",
    "        df = df.copy()\n",
    "        \n",
    "        # Cálculos básicos\n",
    "        df['range'] = df['high'] - df['low']\n",
    "        df['body'] = abs(df['close'] - df['open'])\n",
    "        df['upper_wick'] = df['high'] - df[['open', 'close']].max(axis=1)\n",
    "        df['lower_wick'] = df[['open', 'close']].min(axis=1) - df['low']\n",
    "        \n",
    "        # Volume\n",
    "        df['volume_ema'] = df['tick_volume'].ewm(span=20).mean()\n",
    "        df['volume_ratio'] = df['tick_volume'] / df['volume_ema']\n",
    "        \n",
    "        # Momentum e tendência\n",
    "        df['price_change'] = df['close'].pct_change()\n",
    "        df['price_change_pct'] = df['price_change'] * 100\n",
    "        \n",
    "        for period in [8, 20, 50]:\n",
    "            df[f'ma_{period}'] = df['close'].rolling(window=period).mean()\n",
    "        \n",
    "        df['volatility'] = df['range'].rolling(window=20).std()\n",
    "        df['atr'] = df['range'].rolling(window=14).mean()\n",
    "        \n",
    "        df['trend'] = np.where(df['ma_20'] > df['ma_50'], 1, \n",
    "                             np.where(df['ma_20'] < df['ma_50'], -1, 0))\n",
    "                \n",
    "        return df\n",
    "\n",
    "    def get_filename(self, symbol, timeframe, date):\n",
    "        \"\"\"Gera nome do arquivo padronizado\"\"\"\n",
    "        tf_name = {v: k for k, v in TIMEFRAMES.items()}[timeframe]\n",
    "        return f\"{symbol.replace('$', '')}_{tf_name}_{date.strftime('%Y%m%d')}.csv\"\n",
    "\n",
    "   \n",
    "    def save_data(self, df, symbol, timeframe, date):\n",
    "        \"\"\"Salva dados com nome padronizado\"\"\"\n",
    "        if df is None:\n",
    "            return None\n",
    "            \n",
    "        filename = self.get_filename(symbol, timeframe, date)\n",
    "        filepath = os.path.join(DATA_DIR, filename)\n",
    "        \n",
    "        # Renomear colunas para padrão B3\n",
    "        column_mapping = {\n",
    "            'open': 'PREÇO ABERT.',\n",
    "            'high': 'PREÇO MÁX.',\n",
    "            'low': 'PREÇO MÍN.',\n",
    "            'close': 'ÚLT. PREÇO',\n",
    "            'tick_volume': 'VOL.',\n",
    "            'time': 'DATA'\n",
    "        }\n",
    "        \n",
    "        df_save = df.rename(columns=column_mapping)\n",
    "        df_save['AJUSTE'] = df_save['ÚLT. PREÇO']\n",
    "        df_save['VENCTO'] = symbol.split('$')[0]\n",
    "        df_save['TIMEFRAME'] = {v: k for k, v in TIMEFRAMES.items()}[timeframe]\n",
    "        \n",
    "        primary_columns = ['VENCTO', 'DATA', 'TIMEFRAME', 'PREÇO ABERT.', 'PREÇO MÍN.', \n",
    "                          'PREÇO MÁX.', 'ÚLT. PREÇO', 'AJUSTE', 'VOL.']\n",
    "        other_columns = [col for col in df_save.columns if col not in primary_columns]\n",
    "        df_save = df_save[primary_columns + other_columns]\n",
    "\n",
    "        df_save = adicionar_colunas_avancadas(df_save)\n",
    "        \n",
    "        df_save.to_csv(filepath, index=False)\n",
    "        return filepath\n",
    "\n",
    "    def collect_historical_data(self, days=30):\n",
    "        \"\"\"Coleta dados históricos verificando arquivos existentes\"\"\"\n",
    "        symbols = ['WDO$N']\n",
    "        collected_files = {}\n",
    "        \n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days)\n",
    "        current_date = start_date\n",
    "        \n",
    "        print(f\"\\nIniciando coleta de {days} dias: {start_date.date()} até {end_date.date()}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        while current_date <= end_date:\n",
    "            print(f\"\\nProcessando data: {current_date.date()}\")\n",
    "            \n",
    "            for symbol in symbols:\n",
    "                for tf_name, timeframe in TIMEFRAMES.items():\n",
    "                    filename = self.get_filename(symbol, timeframe, current_date)\n",
    "                    \n",
    "                    # Verificar se arquivo já existe\n",
    "                    if filename in self.existing_files:\n",
    "                        print(f\"  {symbol} {tf_name}: Arquivo já existe\")\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        print(f\"  Coletando {symbol} {tf_name}...\", end=' ')\n",
    "                        \n",
    "                        df = self.get_timeframe_data(symbol, timeframe, current_date)\n",
    "                        if df is None:\n",
    "                            print(\"Sem dados\")\n",
    "                            continue\n",
    "                            \n",
    "                        df_processed = self.process_data(df)\n",
    "                        if df_processed is None:\n",
    "                            print(\"Erro no processamento\")\n",
    "                            continue\n",
    "                            \n",
    "                        filepath = self.save_data(df_processed, symbol, timeframe, current_date)\n",
    "                        if filepath:\n",
    "                            key = f\"{symbol}_{tf_name}_{current_date.date()}\"\n",
    "                            collected_files[key] = {\n",
    "                                'path': filepath,\n",
    "                                'records': len(df_processed)\n",
    "                            }\n",
    "                            print(f\"OK ({len(df_processed)} registros)\")\n",
    "                            self.existing_files.add(filename)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro: {str(e)}\")\n",
    "                        continue\n",
    "            \n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        return collected_files\n",
    "\n",
    "def print_collection_summary(collected_files):\n",
    "    \"\"\"Imprime resumo da coleta\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RESUMO DA COLETA DE DADOS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not collected_files:\n",
    "        print(\"\\nNenhum novo arquivo coletado - Todos os dados já existem\")\n",
    "        return\n",
    "    \n",
    "    for key, info in collected_files.items():\n",
    "        symbol, tf, date = key.split('_')\n",
    "        filepath = info['path']\n",
    "        filename = os.path.basename(filepath)\n",
    "        filesize = os.path.getsize(filepath) / 1024  # KB\n",
    "        \n",
    "        print(f\"\\n{symbol} - {tf} - {date}:\")\n",
    "        print(f\"  Arquivo: {filename}\")\n",
    "        print(f\"  Tamanho: {filesize:.1f} KB\")\n",
    "        print(f\"  Registros: {info['records']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        collector = MTDataCollector()\n",
    "        collected_files = collector.collect_historical_data(days=7)\n",
    "        print_collection_summary(collected_files)\n",
    "        \n",
    "        print(\"\\nProcesso finalizado com sucesso!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro durante a coleta: {str(e)}\")\n",
    "        print(\"Verifique se o MetaTrader5 está aberto e configurado corretamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51921d0-10f0-4e93-b4f5-22add774ac9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
